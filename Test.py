import torch
import os
import cv2
import numpy as np
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import sklearn.metrics as metrics
from sklearn.metrics import precision_recall_curve, average_precision_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import time
import seaborn as sns
from matplotlib.ticker import MaxNLocator

from GenerateEEMNet import EEMLite_Generator


def load_model(model_path, device="cuda"):
    model = EEMLite_Generator(ch_in=3, ch_out=1)
    checkpoint = torch.load(model_path, map_location=device)
    print("æƒé‡æ–‡ä»¶ä¸­çš„é”®åï¼š", checkpoint.keys())
    model.load_state_dict(checkpoint['generator_state_dict'], strict=False)
    model.to(device)
    model.eval()
    print(f"æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    return model


def preprocess_image_and_mask(img_path, mask_path, size=(512, 640), ignore_value=None):
    """
    é¢„å¤„ç†å›¾ç‰‡å’Œå¯¹åº”çš„æ ‡ç­¾æ©è†œ
    """
    # é¢„å¤„ç†å›¾åƒ
    transform = transforms.Compose([
        transforms.Resize(size),
        transforms.ToTensor()
    ])
    img = Image.open(img_path).convert("RGB")
    tensor = transform(img).unsqueeze(0)  # [1,3,H,W]

    if ignore_value is not None:
        ignore_norm = ignore_value / 255.0
        mask = (tensor == ignore_norm)
        tensor = tensor.clone()
        tensor[mask] = 0.0
        mask_any = mask.any(dim=1, keepdim=True)  # [1,1,H,W]
    else:
        mask_any = torch.zeros((1, 1, *tensor.shape[2:]), dtype=torch.bool)

    # é¢„å¤„ç†æ©è†œ
    if mask_path and os.path.exists(mask_path):
        mask_img = Image.open(mask_path).convert("L")  # è½¬ä¸ºç°åº¦å›¾
        mask_tensor = transforms.Resize(size)(mask_img)
        mask_tensor = transforms.ToTensor()(mask_tensor).unsqueeze(0)  # [1,1,H,W]
        # äºŒå€¼åŒ–æ©è†œï¼šè£‚ç¼åŒºåŸŸä¸º1ï¼ŒèƒŒæ™¯ä¸º0
        mask_binary = (mask_tensor > 0).float()
    else:
        mask_binary = None

    return img, tensor, mask_any, mask_binary


def calculate_classification_metrics(prediction, target, threshold=0.25):
    """
    è®¡ç®—å¤šç±»åˆ«åˆ†ç±»æŒ‡æ ‡ï¼ˆèƒŒæ™¯ç±»=0ï¼Œè£‚ç¼ç±»=1ï¼‰
    """
    # ç¡®ä¿æ•°æ®æ˜¯numpyæ•°ç»„
    if isinstance(prediction, torch.Tensor):
        prediction = prediction.cpu().numpy()
    if isinstance(target, torch.Tensor):
        target = target.cpu().numpy()

    # å±•å¹³æ•°ç»„
    pred_flat = prediction.flatten()
    target_flat = target.flatten()

    # äºŒå€¼åŒ–é¢„æµ‹ç»“æœ
    pred_binary = (pred_flat < threshold).astype(np.uint8)
    target_binary = (target_flat > 0).astype(np.uint8)

    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(target_binary, pred_binary, labels=[0, 1])
    tn, fp, fn, tp = cm.ravel()

    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    total_pixels = len(pred_flat)
    accuracy = (tp + tn) / total_pixels if total_pixels > 0 else 0

    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    metrics_by_class = {}

    # èƒŒæ™¯ç±» (class 0)
    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0
    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0
    support_0 = tn + fp  # çœŸå®èƒŒæ™¯åƒç´ æ•°é‡

    metrics_by_class[0] = {
        'precision': precision_0,
        'recall': recall_0,
        'f1_score': f1_0,
        'support': support_0
    }

    # è£‚ç¼ç±» (class 1)
    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0
    support_1 = tp + fn  # çœŸå®è£‚ç¼åƒç´ æ•°é‡

    metrics_by_class[1] = {
        'precision': precision_1,
        'recall': recall_1,
        'f1_score': f1_1,
        'support': support_1
    }

    # è®¡ç®—å®è§‚å¹³å‡æŒ‡æ ‡
    macro_precision = (precision_0 + precision_1) / 2
    macro_recall = (recall_0 + recall_1) / 2
    macro_f1 = (f1_0 + f1_1) / 2

    # è®¡ç®—åŠ æƒå¹³å‡æŒ‡æ ‡
    weight_0 = support_0 / total_pixels
    weight_1 = support_1 / total_pixels
    weighted_precision = precision_0 * weight_0 + precision_1 * weight_1
    weighted_recall = recall_0 * weight_0 + recall_1 * weight_1
    weighted_f1 = f1_0 * weight_0 + f1_1 * weight_1

    # è®¡ç®—IoUæŒ‡æ ‡
    intersection_0 = tn
    union_0 = tn + fn + fp
    iou_0 = intersection_0 / union_0 if union_0 > 0 else 0

    intersection_1 = tp
    union_1 = tp + fp + fn
    iou_1 = intersection_1 / union_1 if union_1 > 0 else 0

    # æ·»åŠ IoUåˆ°ç±»åˆ«æŒ‡æ ‡
    metrics_by_class[0]['iou'] = iou_0
    metrics_by_class[1]['iou'] = iou_1

    # è®¡ç®—å¹³å‡IoU
    mean_iou = (iou_0 + iou_1) / 2

    # è®¡ç®—æ•´ä½“IoU (æ‰€æœ‰ç±»åˆ«çš„äº¤é›†/å¹¶é›†)
    intersection_total = tp + tn
    union_total = tp + fp + fn + tn
    overall_iou = intersection_total / union_total if union_total > 0 else 0

    # è®¡ç®—Diceç³»æ•°
    dice = 2 * (tp + tn) / (2 * (tp + tn) + fp + fn) if (2 * (tp + tn) + fp + fn) > 0 else 0

    return {
        'overall': {
            'accuracy': accuracy,
            'overall_iou': overall_iou,
            'mean_iou': mean_iou,
            'dice': dice,
            'macro_precision': macro_precision,
            'macro_recall': macro_recall,
            'macro_f1': macro_f1,
            'weighted_precision': weighted_precision,
            'weighted_recall': weighted_recall,
            'weighted_f1': weighted_f1,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn,
            'total_pixels': total_pixels
        },
        'class_metrics': metrics_by_class
    }


def calculate_pr_curve(predictions, targets):
    """
    è®¡ç®—ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿å’ŒAPå€¼
    """
    all_preds = []
    all_targets = []

    for pred, target in zip(predictions, targets):
        if isinstance(pred, torch.Tensor):
            pred = pred.cpu().numpy()
        if isinstance(target, torch.Tensor):
            target = target.cpu().numpy()

        all_preds.extend(pred.flatten())
        all_targets.extend(target.flatten())

    all_preds = np.array(all_preds)
    all_targets = np.array(all_targets)

    # è®¡ç®—AP
    ap = average_precision_score(all_targets, all_preds)

    # è®¡ç®—PRæ›²çº¿
    precision_vals, recall_vals, _ = precision_recall_curve(all_targets, all_preds)

    return ap, precision_vals, recall_vals


def create_elegant_metrics_plots(metrics_history, speed_metrics, save_dir):
    """
    åˆ›å»ºä¼˜é›…çš„æŒ‡æ ‡å¯è§†åŒ–å›¾è¡¨
    """
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

    # 1. ä¸»è¦æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿', fontsize=16, fontweight='bold')

    # å‡†ç¡®ç‡å’ŒF1åˆ†æ•°
    if metrics_history['overall_accuracy'] and metrics_history['class_1_f1']:
        x_range = range(1, len(metrics_history['overall_accuracy']) + 1)
        axes[0, 0].plot(x_range, metrics_history['overall_accuracy'], 'o-', linewidth=2, markersize=4, label='å‡†ç¡®ç‡')
        axes[0, 0].plot(x_range, metrics_history['class_1_f1'], 's-', linewidth=2, markersize=4, label='è£‚ç¼F1')
        axes[0, 0].plot(x_range, metrics_history['class_0_f1'], '^-', linewidth=2, markersize=4, label='èƒŒæ™¯F1')
        axes[0, 0].plot(x_range, metrics_history['macro_f1'], 'v-', linewidth=2, markersize=4, label='å®è§‚F1')
        axes[0, 0].set_xlabel('å›¾åƒåºå·')
        axes[0, 0].set_ylabel('åˆ†æ•°')
        axes[0, 0].set_title('å‡†ç¡®ç‡ & F1åˆ†æ•°è¶‹åŠ¿')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].xaxis.set_major_locator(MaxNLocator(integer=True))

    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    if metrics_history['class_1_precision'] and metrics_history['class_1_recall']:
        x_range = range(1, len(metrics_history['class_1_precision']) + 1)
        axes[0, 1].plot(x_range, metrics_history['class_1_precision'], 'o-', linewidth=2, markersize=4,
                        label='è£‚ç¼ç²¾ç¡®ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_1_recall'], 's-', linewidth=2, markersize=4, label='è£‚ç¼å¬å›ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_0_precision'], '^-', linewidth=2, markersize=4,
                        label='èƒŒæ™¯ç²¾ç¡®ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_0_recall'], 'd-', linewidth=2, markersize=4, label='èƒŒæ™¯å¬å›ç‡')
        axes[0, 1].set_xlabel('å›¾åƒåºå·')
        axes[0, 1].set_ylabel('åˆ†æ•°')
        axes[0, 1].set_title('ç²¾ç¡®ç‡ & å¬å›ç‡è¶‹åŠ¿')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].xaxis.set_major_locator(MaxNLocator(integer=True))

    # IoUå’ŒDiceç³»æ•°
    if metrics_history['class_1_iou'] and metrics_history['overall_dice']:
        x_range = range(1, len(metrics_history['class_1_iou']) + 1)
        axes[1, 0].plot(x_range, metrics_history['class_1_iou'], 'o-', linewidth=2, markersize=4, label='è£‚ç¼IoU')
        axes[1, 0].plot(x_range, metrics_history['class_0_iou'], 's-', linewidth=2, markersize=4, label='èƒŒæ™¯IoU')
        axes[1, 0].plot(x_range, metrics_history['mean_iou'], '^-', linewidth=2, markersize=4, label='å¹³å‡IoU')
        axes[1, 0].plot(x_range, metrics_history['overall_dice'], 'v-', linewidth=2, markersize=4, label='Diceç³»æ•°')
        axes[1, 0].set_xlabel('å›¾åƒåºå·')
        axes[1, 0].set_ylabel('åˆ†æ•°')
        axes[1, 0].set_title('åˆ†å‰²æŒ‡æ ‡è¶‹åŠ¿')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].xaxis.set_major_locator(MaxNLocator(integer=True))

    # æ¨ç†é€Ÿåº¦è¶‹åŠ¿
    if speed_metrics['inference_times']:
        x_range = range(1, len(speed_metrics['inference_times']) + 1)
        axes[1, 1].plot(x_range, speed_metrics['inference_times'], '^-', color='purple',
                        linewidth=2, markersize=4, label='æ¨ç†æ—¶é—´')
        axes[1, 1].set_xlabel('å›¾åƒåºå·')
        axes[1, 1].set_ylabel('æ—¶é—´ (ç§’)')
        axes[1, 1].set_title('æ¨ç†æ—¶é—´è¶‹åŠ¿')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].xaxis.set_major_locator(MaxNLocator(integer=True))

    plt.tight_layout()
    performance_plot_path = os.path.join(save_dir, "elegant_performance_metrics.png")
    plt.savefig(performance_plot_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # 2. é€Ÿåº¦æŒ‡æ ‡æ±‡æ€»å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig.suptitle('æ¨¡å‹æ¨ç†é€Ÿåº¦åˆ†æ', fontsize=16, fontweight='bold')

    # æ¨ç†æ—¶é—´åˆ†å¸ƒ
    if speed_metrics['inference_times']:
        axes[0].hist(speed_metrics['inference_times'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0].axvline(np.mean(speed_metrics['inference_times']), color='red', linestyle='--',
                        linewidth=2, label=f'å¹³å‡æ—¶é—´: {np.mean(speed_metrics["inference_times"]):.4f}s')
        axes[0].set_xlabel('æ¨ç†æ—¶é—´ (ç§’)')
        axes[0].set_ylabel('é¢‘æ¬¡')
        axes[0].set_title('æ¨ç†æ—¶é—´åˆ†å¸ƒ')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

    # FPSåˆ†å¸ƒ
    if speed_metrics['fps_list']:
        axes[1].hist(speed_metrics['fps_list'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[1].axvline(np.mean(speed_metrics['fps_list']), color='red', linestyle='--',
                        linewidth=2, label=f'å¹³å‡FPS: {np.mean(speed_metrics["fps_list"]):.2f}')
        axes[1].set_xlabel('FPS')
        axes[1].set_ylabel('é¢‘æ¬¡')
        axes[1].set_title('FPSåˆ†å¸ƒ')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    speed_plot_path = os.path.join(save_dir, "elegant_speed_analysis.png")
    plt.savefig(speed_plot_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # 3. ç±»åˆ«æ€§èƒ½å¯¹æ¯”å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig.suptitle('ç±»åˆ«æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')

    # ç²¾ç¡®ç‡å’Œå¬å›ç‡å¯¹æ¯”
    categories = ['èƒŒæ™¯', 'è£‚ç¼']
    precision_values = [np.mean(metrics_history['class_0_precision']), np.mean(metrics_history['class_1_precision'])]
    recall_values = [np.mean(metrics_history['class_0_recall']), np.mean(metrics_history['class_1_recall'])]

    x = np.arange(len(categories))
    width = 0.35

    axes[0].bar(x - width / 2, precision_values, width, label='ç²¾ç¡®ç‡', alpha=0.7)
    axes[0].bar(x + width / 2, recall_values, width, label='å¬å›ç‡', alpha=0.7)
    axes[0].set_xlabel('ç±»åˆ«')
    axes[0].set_ylabel('åˆ†æ•°')
    axes[0].set_title('å„ç±»åˆ«ç²¾ç¡®ç‡å’Œå¬å›ç‡')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(categories)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # F1åˆ†æ•°å’ŒIoUå¯¹æ¯”
    f1_values = [np.mean(metrics_history['class_0_f1']), np.mean(metrics_history['class_1_f1'])]
    iou_values = [np.mean(metrics_history['class_0_iou']), np.mean(metrics_history['class_1_iou'])]

    axes[1].bar(x - width / 2, f1_values, width, label='F1åˆ†æ•°', alpha=0.7)
    axes[1].bar(x + width / 2, iou_values, width, label='IoU', alpha=0.7)
    axes[1].set_xlabel('ç±»åˆ«')
    axes[1].set_ylabel('åˆ†æ•°')
    axes[1].set_title('å„ç±»åˆ«F1åˆ†æ•°å’ŒIoU')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(categories)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    class_comparison_path = os.path.join(save_dir, "class_performance_comparison.png")
    plt.savefig(class_comparison_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"ğŸ¨ ä¼˜é›…æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}")
    return [performance_plot_path, speed_plot_path, class_comparison_path]


def save_pure_heatmap(data, original_img, save_path):
    """
    ä¿å­˜çº¯çƒ­å›¾ï¼ˆä¸å åŠ åŸå›¾ï¼‰ï¼Œå°ºå¯¸ä¸åŸå›¾ä¸€è‡´
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    if isinstance(data, torch.Tensor):
        data = data.squeeze().cpu().numpy()

    norm = (data - data.min()) / (data.max() - data.min() + 1e-8)
    heatmap_uint8 = (norm * 255).astype(np.uint8)

    orig_w, orig_h = original_img.size
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_color = cv2.resize(heatmap_color, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)

    cv2.imwrite(save_path, heatmap_color)
    print(f"å·²ä¿å­˜çº¯çƒ­å›¾: {save_path}")








def save_image(attn_tensor, mask_tensor, save_path, original_img=None,
               keep_white=True, heat_threshold=0.18, blend_alpha=0.8,
               enhance_strength=3.5, soften=False, soften_ksize=15):
    """
    ç¨³å¥ç‰ˆï¼šä»…å°† attn ä¸­ > heat_threshold çš„åƒç´ å¯¹åŸå›¾å¯¹åº”ä½ç½®è¿›è¡Œé»‘è‰²åŠ æ·±å¤„ç†ï¼ˆè®©åŒºåŸŸæ›´é»‘ï¼‰
    """
    import os
    import numpy as np
    import cv2
    from PIL import Image
    import torch

    dirpath = os.path.dirname(save_path)
    if dirpath:
        os.makedirs(dirpath, exist_ok=True)

    if original_img is None:
        raise ValueError("original_img ä¸èƒ½ä¸ºç©ºã€‚")
    if isinstance(original_img, Image.Image):
        img_rgb = np.array(original_img.convert("RGB"))
    else:
        img_rgb = np.asarray(original_img)
        if img_rgb.ndim == 2:
            img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_GRAY2RGB)
        elif img_rgb.shape[2] == 4:
            img_rgb = img_rgb[..., :3]

    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    H, W = img_bgr.shape[:2]

    if isinstance(attn_tensor, torch.Tensor):
        attn_np = attn_tensor.detach().cpu().numpy()
    else:
        attn_np = np.asarray(attn_tensor)

    while attn_np.ndim > 2:
        attn_np = attn_np.mean(axis=0)
    attn_np = attn_np.astype(np.float32)

    if not np.isfinite(attn_np).all():
        attn_np = np.nan_to_num(attn_np, nan=0.0, posinf=0.0, neginf=0.0)
    mn = float(np.nanmin(attn_np)) if attn_np.size else 0.0
    mx = float(np.nanmax(attn_np)) if attn_np.size else 0.0
    if mx - mn < 1e-8:
        attn_norm = np.zeros_like(attn_np, dtype=np.float32)
    else:
        attn_norm = (attn_np - mn) / (mx - mn)

    attn_resized = cv2.resize(attn_norm.astype(np.float32), (W, H), interpolation=cv2.INTER_LINEAR)

    heat_mask = (attn_resized < float(heat_threshold))
    if soften:
        k = soften_ksize if (soften_ksize % 2 == 1) else (soften_ksize + 1)
        heat_mask_float = cv2.GaussianBlur(heat_mask.astype(np.float32), (k, k), 0)
        heat_alpha = np.clip(heat_mask_float, 0.0, 1.0) * float(blend_alpha)
    else:
        heat_alpha = heat_mask.astype(np.float32) * float(blend_alpha)

    # -------------------------- æ ¸å¿ƒä¿®æ”¹ï¼šé»‘è‰²åŠ æ·±é€»è¾‘ --------------------------
    # 1. ç”Ÿæˆ"çº¯é»‘è‰²æ¨¡æ¿"ï¼ˆä¸åŸå›¾åŒå°ºå¯¸ï¼Œæ‰€æœ‰åƒç´ ä¸º(0,0,0)ï¼‰
    black_template = np.zeros_like(img_bgr, dtype=np.uint8)
    # 2. è®¡ç®—é»‘è‰²åŠ æ·±ç³»æ•°ï¼šç³»æ•°è¶Šå¤§ï¼ŒåŠ æ·±æ•ˆæœè¶Šå¼ºï¼ˆ1.0=ä¸åŠ æ·±ï¼Œ>1.0=æ›´é»‘ï¼‰
    # enhance_strengthè¶Šå¤§ã€heat_alphaè¶Šé«˜ï¼ŒåŠ æ·±ç³»æ•°è¶Šå¤§
    darken_factor = 1.0 + (enhance_strength - 1.0) * heat_alpha
    # ç¡®ä¿ç³»æ•°ä¸å°äº1.0ï¼ˆé¿å…åå‘å˜äº®ï¼‰
    darken_factor = np.clip(darken_factor, 1.0, None)

    # 3. å¯¹åŸå›¾è¿›è¡Œé»‘è‰²åŠ æ·±ï¼šåƒç´ å€¼ = åŸå›¾åƒç´ å€¼ / åŠ æ·±ç³»æ•°ï¼ˆå€¼è¶Šå°è¶Šé»‘ï¼‰
    # å…ˆè½¬floaté¿å…æ•´æ•°é™¤æ³•å¤±çœŸï¼Œè®¡ç®—åclipåˆ°0-255èŒƒå›´
    img_float = img_bgr.astype(np.float32)
    # æ‰©å±•ç³»æ•°ç»´åº¦ä»¥åŒ¹é…BGRä¸‰é€šé“ï¼ˆ(H,W) â†’ (H,W,1)ï¼‰
    darken_factor_3d = darken_factor[..., np.newaxis]
    # æ‰§è¡ŒåŠ æ·±è®¡ç®—
    darkened_bgr = np.clip(img_float / darken_factor_3d, 0, 255).astype(np.uint8)
    # --------------------------------------------------------------------------

    # åº”ç”¨é»‘è‰²åŠ æ·±æ•ˆæœåˆ°æ³¨æ„åŠ›åŒºåŸŸ
    overlay = img_bgr.copy()
    mask_idxs = heat_mask
    if mask_idxs.any():
        # ç›´æ¥ä½¿ç”¨æ•°ç»„è¿ç®—å®ç°åŠ æƒæ··åˆï¼ˆæ›¿ä»£cv2.addWeightedï¼‰
        # æå–æ©ç åŒºåŸŸçš„åŸå›¾å’ŒåŠ æ·±å›¾åƒç´ 
        original_pixels = img_bgr[mask_idxs].astype(np.float32)
        darkened_pixels = darkened_bgr[mask_idxs].astype(np.float32)
        # è·å–å¯¹åº”ä½ç½®çš„alphaå€¼å¹¶æ‰©å±•ç»´åº¦ä»¥åŒ¹é…åƒç´ å½¢çŠ¶
        alpha_values = heat_alpha[mask_idxs][:, np.newaxis]
        # è®¡ç®—æ··åˆåƒç´ å€¼ï¼šalphaè¶Šå¤§ï¼ŒåŠ æ·±æ•ˆæœè¶Šæ˜æ˜¾
        blended_pixels = (original_pixels * (1.0 - alpha_values) +
                         darkened_pixels * alpha_values).astype(np.uint8)
        # å°†æ··åˆç»“æœèµ‹å€¼å›åŸå›¾
        overlay[mask_idxs] = blended_pixels

    if mask_tensor is not None:
        if isinstance(mask_tensor, torch.Tensor):
            mask_np = mask_tensor.detach().cpu().numpy()
        else:
            mask_np = np.asarray(mask_tensor)

        mask_np = np.squeeze(mask_np)
        while mask_np.ndim > 2:
            mask_np = mask_np.any(axis=0)
        mask_resized = cv2.resize(mask_np.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)

        if mask_resized.any():
            if keep_white:
                overlay[mask_resized] = (255, 255, 255)
            else:
                overlay[mask_resized] = (0, 0, 0)

    overlay = overlay.astype(np.uint8)
    cv2.imwrite(save_path, overlay)
    print(f"å·²ä¿å­˜: {save_path}")

    return overlay


def find_mask_for_image(img_path, mask_dir):
    """
    æ ¹æ®å›¾åƒæ–‡ä»¶åæ‰¾åˆ°å¯¹åº”çš„æ©è†œæ–‡ä»¶
    é€‚é…æ‚¨çš„å‘½åçº¦å®šï¼šimage: '20160222_080850.jpg' -> mask: '20160222_080850_mask.png'
    """
    img_name = os.path.basename(img_path)
    base_name = os.path.splitext(img_name)[0]  # å»æ‰æ‰©å±•åï¼Œå¾—åˆ° '20160222_080850'

    # å¯èƒ½çš„æ©è†œæ–‡ä»¶åæ¨¡å¼
    possible_mask_names = [
        f"{base_name}_mask.png",  # æ‚¨çš„å‘½åçº¦å®š
        f"{base_name}_mask.jpg",
        f"{base_name}.png",  # å¤‡ç”¨æ–¹æ¡ˆ
        f"{base_name}.jpg",
        base_name + '.png',  # ç›´æ¥ä½¿ç”¨ç›¸åŒæ–‡ä»¶å
        base_name + '.jpg'
    ]

    for mask_name in possible_mask_names:
        mask_path = os.path.join(mask_dir, mask_name)
        if os.path.exists(mask_path):
            return mask_path

    return None


def calculate_average_metrics(metrics_list):
    """
    è®¡ç®—æŒ‡æ ‡åˆ—è¡¨çš„å¹³å‡å€¼ï¼Œåªå¤„ç†æ•°å€¼ç±»å‹çš„æŒ‡æ ‡
    """
    if not metrics_list:
        return {}

    # è·å–æ‰€æœ‰æ•°å€¼ç±»å‹çš„é”®
    numeric_keys = []
    for key in metrics_list[0].keys():
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„å€¼æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹
        if isinstance(metrics_list[0][key], (int, float, np.number)):
            numeric_keys.append(key)

    # è®¡ç®—å¹³å‡å€¼
    avg_metrics = {}
    for key in numeric_keys:
        try:
            avg_metrics[key] = np.mean([m[key] for m in metrics_list])
        except (TypeError, ValueError):
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè·³è¿‡è¯¥é”®
            continue

    return avg_metrics


@torch.no_grad()
def test_fgem_with_mask(
        model_path,
        input_path,
        mask_dir=None,  # æ–°å¢ï¼šæ©è†œæ–‡ä»¶ç›®å½•
        device="cuda",
        save_dir_input="./run/predict_heatmap/input",
        save_dir_output="./run/predict_heatmap/output",
        save_dir_orig="./run/predict_images/original",
        save_dir_result="./run/predict_images/result",
        save_dir_metrics="./run/metrics",  # æ–°å¢ï¼šæŒ‡æ ‡ä¿å­˜ç›®å½•
        eval_threshold=0.25  # æ–°å¢ï¼šè¯„ä¼°é˜ˆå€¼
):
    model = load_model(model_path, device)

    # åˆå§‹åŒ–æŒ‡æ ‡å­˜å‚¨
    all_overall_metrics = []
    all_class_metrics = {0: [], 1: []}  # 0:èƒŒæ™¯, 1:è£‚ç¼

    metrics_history = {
        'overall_accuracy': [], 'overall_iou': [], 'mean_iou': [], 'overall_dice': [],
        'macro_precision': [], 'macro_recall': [], 'macro_f1': [],
        'weighted_precision': [], 'weighted_recall': [], 'weighted_f1': [],
        'class_0_precision': [], 'class_0_recall': [], 'class_0_f1': [], 'class_0_iou': [],
        'class_1_precision': [], 'class_1_recall': [], 'class_1_f1': [], 'class_1_iou': []
    }

    # æ–°å¢ï¼šé€Ÿåº¦æŒ‡æ ‡å­˜å‚¨
    speed_metrics = {
        'inference_times': [],
        'fps_list': [],
        'preprocess_times': [],
        'postprocess_times': []
    }

    all_predictions = []
    all_targets = []

    if os.path.isdir(input_path):
        img_list = [os.path.join(input_path, f)
                    for f in os.listdir(input_path)
                    if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    else:
        img_list = [input_path]

    valid_count = 0
    missing_masks = []

    for img_path in tqdm(img_list, desc="Testing FGEM"):
        # æ„å»ºå¯¹åº”çš„æ©è†œè·¯å¾„
        if mask_dir:
            mask_path = find_mask_for_image(img_path, mask_dir)
            if mask_path is None:
                missing_masks.append(os.path.basename(img_path))
                print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”æ©è†œæ–‡ä»¶: {os.path.basename(img_path)}")
        else:
            mask_path = None

        # é¢„å¤„ç†è®¡æ—¶
        preprocess_start = time.perf_counter()
        original_img, tensor, ignore_mask, mask_binary = preprocess_image_and_mask(
            img_path, mask_path, ignore_value=None
        )
        tensor = tensor.to(device)
        ignore_mask = ignore_mask.to(device)
        preprocess_time = time.perf_counter() - preprocess_start
        speed_metrics['preprocess_times'].append(preprocess_time)

        # ---- æ¨ç†ï¼ˆç²¾ç¡®è®¡æ—¶ï¼‰----
        inference_start = time.perf_counter()
        out = model(tensor)
        # attn_map = model.attn_sigmoid(model.attn_conv(out))
        # attn_map = attn_map.mean(dim=1, keepdim=True)
        attn_map = out.mean(dim=1, keepdim=True)

        inference_time = time.perf_counter() - inference_start
        speed_metrics['inference_times'].append(inference_time)
        speed_metrics['fps_list'].append(1.0 / inference_time)

        # åå¤„ç†è®¡æ—¶
        postprocess_start = time.perf_counter()

        # ä¿å­˜åŸå›¾
        orig_save_path = os.path.join(save_dir_orig, os.path.basename(img_path))
        os.makedirs(os.path.dirname(orig_save_path), exist_ok=True)
        original_img.save(orig_save_path)

        # ä¿å­˜ç»“æœå›¾
        result_save_path = os.path.join(save_dir_result, os.path.basename(img_path))
        save_image(attn_map, ignore_mask, result_save_path, original_img=original_img, keep_white=True)




        # ä¿å­˜è¾“å…¥çƒ­å›¾
        input_gray = tensor.mean(dim=1, keepdim=True)
        save_pure_heatmap(input_gray, original_img,
                          os.path.join(save_dir_input, os.path.basename(img_path).split(".")[0] + "_input_heatmap.png"))

        # ä¿å­˜è¾“å‡ºçƒ­å›¾
        save_pure_heatmap(attn_map, original_img,
                          os.path.join(save_dir_output,
                                       os.path.basename(img_path).split(".")[0] + "_output_heatmap.png"))

        postprocess_time = time.perf_counter() - postprocess_start
        speed_metrics['postprocess_times'].append(postprocess_time)

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰æ©è†œï¼‰
        if mask_binary is not None:
            # å°†é¢„æµ‹ç»“æœè°ƒæ•´åˆ°ä¸æ©è†œç›¸åŒçš„å°ºå¯¸
            pred_resized = torch.nn.functional.interpolate(
                attn_map, size=mask_binary.shape[2:], mode='bilinear', align_corners=False
            )

            # è®¡ç®—æŒ‡æ ‡ï¼ˆåˆ†ç±»è§†è§’ï¼‰
            metrics_result = calculate_classification_metrics(pred_resized, mask_binary, threshold=eval_threshold)

            # åˆ†åˆ«å­˜å‚¨å„ç±»æŒ‡æ ‡
            all_overall_metrics.append(metrics_result['overall'])

            for class_id in [0, 1]:
                all_class_metrics[class_id].append(metrics_result['class_metrics'][class_id])

            # æ›´æ–°å†å²è®°å½•
            metrics_history['overall_accuracy'].append(metrics_result['overall']['accuracy'])
            metrics_history['overall_iou'].append(metrics_result['overall']['overall_iou'])
            metrics_history['mean_iou'].append(metrics_result['overall']['mean_iou'])
            metrics_history['overall_dice'].append(metrics_result['overall']['dice'])

            metrics_history['macro_precision'].append(metrics_result['overall']['macro_precision'])
            metrics_history['macro_recall'].append(metrics_result['overall']['macro_recall'])
            metrics_history['macro_f1'].append(metrics_result['overall']['macro_f1'])

            metrics_history['weighted_precision'].append(metrics_result['overall']['weighted_precision'])
            metrics_history['weighted_recall'].append(metrics_result['overall']['weighted_recall'])
            metrics_history['weighted_f1'].append(metrics_result['overall']['weighted_f1'])

            # ç±»åˆ«0ï¼ˆèƒŒæ™¯ï¼‰
            metrics_history['class_0_precision'].append(metrics_result['class_metrics'][0]['precision'])
            metrics_history['class_0_recall'].append(metrics_result['class_metrics'][0]['recall'])
            metrics_history['class_0_f1'].append(metrics_result['class_metrics'][0]['f1_score'])
            metrics_history['class_0_iou'].append(metrics_result['class_metrics'][0]['iou'])

            # ç±»åˆ«1ï¼ˆè£‚ç¼ï¼‰
            metrics_history['class_1_precision'].append(metrics_result['class_metrics'][1]['precision'])
            metrics_history['class_1_recall'].append(metrics_result['class_metrics'][1]['recall'])
            metrics_history['class_1_f1'].append(metrics_result['class_metrics'][1]['f1_score'])
            metrics_history['class_1_iou'].append(metrics_result['class_metrics'][1]['iou'])

            # å­˜å‚¨é¢„æµ‹å’Œç›®æ ‡å€¼ç”¨äºPRæ›²çº¿
            all_predictions.append(pred_resized)
            all_targets.append(mask_binary)

            valid_count += 1

            print(f"{os.path.basename(img_path)} - "
                  f"è£‚ç¼F1: {metrics_result['class_metrics'][1]['f1_score']:.4f}, "
                  f"èƒŒæ™¯F1: {metrics_result['class_metrics'][0]['f1_score']:.4f}, "
                  f"å®è§‚F1: {metrics_result['overall']['macro_f1']:.4f}, "
                  f"æ¨ç†æ—¶é—´: {inference_time:.4f}s, FPS: {1.0 / inference_time:.2f}")

    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    if valid_count > 0:
        print("/n" + "=" * 80)
        print("æ¨¡å‹è¯„ä¼°ç»“æœæ±‡æ€»ï¼ˆåˆ†ç±»è§†è§’ï¼‰")
        print("=" * 80)

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_overall = calculate_average_metrics(all_overall_metrics)
        avg_class_0 = calculate_average_metrics(all_class_metrics[0])
        avg_class_1 = calculate_average_metrics(all_class_metrics[1])

        # è®¡ç®—é€Ÿåº¦æŒ‡æ ‡
        avg_speed_metrics = {
            'avg_inference_time': np.mean(speed_metrics['inference_times']),
            'std_inference_time': np.std(speed_metrics['inference_times']),
            'avg_fps': np.mean(speed_metrics['fps_list']),
            'std_fps': np.std(speed_metrics['fps_list']),
            'avg_preprocess_time': np.mean(speed_metrics['preprocess_times']),
            'avg_postprocess_time': np.mean(speed_metrics['postprocess_times']),
            'min_inference_time': np.min(speed_metrics['inference_times']),
            'max_inference_time': np.max(speed_metrics['inference_times']),
            'total_inference_time': np.sum(speed_metrics['inference_times'])
        }

        # æ‰“å°è¯¦ç»†æŒ‡æ ‡
        print(f"æµ‹è¯•å›¾åƒæ•°é‡: {valid_count}")

        print(f"\nå…¨å±€æŒ‡æ ‡:")
        print(f"   å‡†ç¡®ç‡ (Accuracy): {avg_overall['accuracy']:.4f}")
        print(f"   æ•´ä½“IoU: {avg_overall['overall_iou']:.4f}")
        print(f"   å¹³å‡IoU: {avg_overall['mean_iou']:.4f}")
        print(f"   Diceç³»æ•°: {avg_overall['dice']:.4f}")
        print(f"   å®è§‚ç²¾ç¡®ç‡: {avg_overall['macro_precision']:.4f}")
        print(f"   å®è§‚å¬å›ç‡: {avg_overall['macro_recall']:.4f}")
        print(f"   å®è§‚F1åˆ†æ•°: {avg_overall['macro_f1']:.4f}")
        print(f"   åŠ æƒç²¾ç¡®ç‡: {avg_overall['weighted_precision']:.4f}")
        print(f"   åŠ æƒå¬å›ç‡: {avg_overall['weighted_recall']:.4f}")
        print(f"   åŠ æƒF1åˆ†æ•°: {avg_overall['weighted_f1']:.4f}")

        print(f"\nèƒŒæ™¯ç±»åˆ«æŒ‡æ ‡ (ç±»åˆ« 0):")
        print(f"   ç²¾ç¡®ç‡: {avg_class_0['precision']:.4f}")
        print(f"   å¬å›ç‡: {avg_class_0['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {avg_class_0['f1_score']:.4f}")
        print(f"   IoU: {avg_class_0['iou']:.4f}")
        print(f"   æ”¯æŒåº¦: {avg_class_0['support']:.0f} åƒç´ ")

        print(f"\nè£‚ç¼ç±»åˆ«æŒ‡æ ‡ (ç±»åˆ« 1):")
        print(f"   ç²¾ç¡®ç‡: {avg_class_1['precision']:.4f}")
        print(f"   å¬å›ç‡: {avg_class_1['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {avg_class_1['f1_score']:.4f}")
        print(f"   IoU: {avg_class_1['iou']:.4f}")
        print(f"   æ”¯æŒåº¦: {avg_class_1['support']:.0f} åƒç´ ")

        print(f"\né€Ÿåº¦æ€§èƒ½æŒ‡æ ‡:")
        print(
            f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_speed_metrics['avg_inference_time']:.4f}s Â± {avg_speed_metrics['std_inference_time']:.4f}s")
        print(f"   æœ€å¿«æ¨ç†æ—¶é—´: {avg_speed_metrics['min_inference_time']:.4f}s")
        print(f"   æœ€æ…¢æ¨ç†æ—¶é—´: {avg_speed_metrics['max_inference_time']:.4f}s")
        print(f"   å¹³å‡FPS: {avg_speed_metrics['avg_fps']:.2f} Â± {avg_speed_metrics['std_fps']:.2f}")
        print(f"   å¹³å‡é¢„å¤„ç†æ—¶é—´: {avg_speed_metrics['avg_preprocess_time']:.4f}s")
        print(f"   å¹³å‡åå¤„ç†æ—¶é—´: {avg_speed_metrics['avg_postprocess_time']:.4f}s")
        print(f"   æ€»æ¨ç†æ—¶é—´: {avg_speed_metrics['total_inference_time']:.2f}s")

        # è®¡ç®—æ€»ä½“çš„TP, FP, FN, TN
        total_tp = sum(m['tp'] for m in all_overall_metrics)
        total_fp = sum(m['fp'] for m in all_overall_metrics)
        total_fn = sum(m['fn'] for m in all_overall_metrics)
        total_tn = sum(m['tn'] for m in all_overall_metrics)
        total_pixels = sum(m['total_pixels'] for m in all_overall_metrics)

        print(f"\næ··æ·†çŸ©é˜µç»Ÿè®¡:")
        print(f"   çœŸé˜³æ€§ (TP): {total_tp}")
        print(f"   å‡é˜³æ€§ (FP): {total_fp}")
        print(f"   å‡é˜´æ€§ (FN): {total_fn}")
        print(f"   çœŸé˜´æ€§ (TN): {total_tn}")
        print(f"   æ€»åƒç´ æ•°: {total_pixels}")

        # è®¡ç®—PRæ›²çº¿å’ŒAP
        ap, precision_curve, recall_curve = calculate_pr_curve(all_predictions, all_targets)
        print(f"å¹³å‡ç²¾åº¦ (AP): {ap:.4f}")

        # ä¿å­˜æŒ‡æ ‡ç»“æœ
        os.makedirs(save_dir_metrics, exist_ok=True)

        # ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶
        metrics_file = os.path.join(save_dir_metrics, "evaluation_results.txt")
        with open(metrics_file, 'w', encoding='utf-8') as f:
            f.write("æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆåˆ†ç±»è§†è§’ï¼‰\n")
            f.write("=" * 50 + "\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°é‡: {valid_count}\n")
            f.write(f"è¯„ä¼°é˜ˆå€¼: {eval_threshold}\n\n")

            f.write("å…¨å±€æŒ‡æ ‡:\n")
            for key, value in avg_overall.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nèƒŒæ™¯ç±»åˆ«æŒ‡æ ‡:\n")
            for key, value in avg_class_0.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nè£‚ç¼ç±»åˆ«æŒ‡æ ‡:\n")
            for key, value in avg_class_1.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\né€Ÿåº¦æŒ‡æ ‡:\n")
            for key, value in avg_speed_metrics.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nAP: {ap:.4f}\n")
            f.write(f"\næ··æ·†çŸ©é˜µ:\n")
            f.write(f"TP: {total_tp}\n")
            f.write(f"FP: {total_fp}\n")
            f.write(f"FN: {total_fn}\n")
            f.write(f"TN: {total_tn}\n")
            f.write(f"æ€»åƒç´ æ•°: {total_pixels}\n")

            # æ·»åŠ ç¼ºå¤±æ©è†œæ–‡ä»¶ä¿¡æ¯
            if missing_masks:
                f.write(f"\nç¼ºå¤±æ©è†œçš„æ–‡ä»¶ ({len(missing_masks)} ä¸ª):\n")
                for missing in missing_masks:
                    f.write(f"{missing}\n")

        print(f"æŒ‡æ ‡ç»“æœå·²ä¿å­˜: {metrics_file}")

        # ä¿å­˜ä¼˜é›…çš„æŒ‡æ ‡å›¾è¡¨
        elegant_plots = create_elegant_metrics_plots(metrics_history, speed_metrics, save_dir_metrics)
        print(f"ä¼˜é›…æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜: {elegant_plots}")

        # ä¿å­˜PRæ›²çº¿
        plt.figure(figsize=(10, 8))
        plt.plot(recall_curve, precision_curve, 'b-', linewidth=2, label=f'PR curve (AP = {ap:.4f})')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend()
        plt.grid(True)
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        pr_curve_path = os.path.join(save_dir_metrics, "pr_curve.png")
        plt.savefig(pr_curve_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"PRæ›²çº¿å·²ä¿å­˜: {pr_curve_path}")

        # æ‰“å°ç¼ºå¤±æ©è†œä¿¡æ¯
        if missing_masks:
            print(f"\næœ‰ {len(missing_masks)} ä¸ªå›¾åƒæœªæ‰¾åˆ°å¯¹åº”æ©è†œæ–‡ä»¶")

    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ©è†œæ–‡ä»¶ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—")


# pre_dir = 'D:/myDataManager/pycharmProject/Crack-Segmentation/FGEM/IOT_duikangGenerateNet/images/test_result'
pre_dir = 'D:/myDataManager/pycharmProject/Crack-Segmentation/road_roi_net/RoadDataset/train/paper3_select/ROI/123___jpg__/frames'

if __name__ == "__main__":
    # test_fgem_with_mask(
    #     model_path="./checkpoints/best_checkpoint.pth",
    #     input_path=r'D:/myDataManager/pycharmProject/Crack-Segmentation/FGEM/IOT_duikangGenerateNet/images',
    #     mask_dir=r'D:/myDataManager/pycharmProject/Crack-Segmentation/FGEM/IOT_duikangGenerateNet/images',  # æŒ‡å®šæ©è†œæ–‡ä»¶ç›®å½•
    #     device="cuda:0" if torch.cuda.is_available() else "cpu",
    #     save_dir_input=  pre_dir + "/predict_heatmap/input",
    #     save_dir_output= pre_dir + "/predict_heatmap/output",
    #     save_dir_orig=   pre_dir + "/predict_images/original",
    #     save_dir_result= pre_dir + "/predict_images/result",
    #     save_dir_metrics=pre_dir + "/metrics",  # æŒ‡æ ‡ä¿å­˜ç›®å½•
    #     eval_threshold=0.25  # è¯„ä¼°é˜ˆå€¼
    # )
    test_fgem_with_mask(
        model_path="./checkpoints/best_checkpoint.pth",
        input_path=r'D:\myDataManager\pycharmProject\Crack-Segmentation\road_roi_net\RoadDataset\train\paper3_select\ROI\123___jpg__\frames',
        mask_dir=r'D:\myDataManager\pycharmProject\Crack-Segmentation\road_roi_net\RoadDataset\train\paper3_select\ROI\123___jpg__\frames',  # æŒ‡å®šæ©è†œæ–‡ä»¶ç›®å½•
        device="cuda:0" if torch.cuda.is_available() else "cpu",
        save_dir_input=pre_dir + "/predict_heatmap/input",
        save_dir_output=pre_dir + "/predict_heatmap/output",
        save_dir_orig=pre_dir + "/predict_images/original",
        save_dir_result=pre_dir + "/predict_images/result",
        save_dir_metrics=pre_dir + "/metrics",  # æŒ‡æ ‡ä¿å­˜ç›®å½•
        eval_threshold=0.25  # è¯„ä¼°é˜ˆå€¼
    )