import torch
import os
import cv2
import numpy as np
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import sklearn.metrics as metrics
from sklearn.metrics import (
    precision_recall_curve,
    average_precision_score,
    classification_report,
    confusion_matrix
)
import matplotlib.pyplot as plt
import time
import seaborn as sns
from matplotlib.ticker import MaxNLocator

# å¯¼å…¥æ¨¡å‹ï¼ˆç¡®ä¿æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼‰
from GenerateEEMNet import EEMLite_Generator


def load_model(model_path, device="cuda"):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼"""
    model = EEMLite_Generator(ch_in=3, ch_out=1)
    checkpoint = torch.load(model_path, map_location=device)
    print("æƒé‡æ–‡ä»¶ä¸­çš„é”®åï¼š", checkpoint.keys())
    model.load_state_dict(checkpoint['generator_state_dict'], strict=False)
    model.to(device)
    model.eval()
    print(f"æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    return model


def preprocess_image_and_mask(img_path, mask_path, size=(512, 640), ignore_value=None):
    """
    é¢„å¤„ç†å›¾ç‰‡å’Œå¯¹åº”çš„æ ‡ç­¾æ©è†œï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šä¿ç•™åŸå§‹Aé€šé“ï¼Œç”¨Aé€šé“æ©è†œRGBï¼‰
    Args:
        img_path: å›¾åƒè·¯å¾„ï¼ˆRGBAæ ¼å¼ï¼‰
        mask_path: æ©è†œè·¯å¾„ï¼ˆå¯ä¸ºNoneï¼‰
        size: é¢„å¤„ç†åå›¾åƒå°ºå¯¸
        ignore_value: éœ€è¦å¿½ç•¥çš„åƒç´ å€¼ï¼ˆå½’ä¸€åŒ–å‰ï¼‰
    Returns:
        img_rgb: ç»Aé€šé“æ©è†œåçš„RGB PILå›¾åƒ
        tensor: é¢„å¤„ç†åçš„å›¾åƒå¼ é‡ [1,3,H,W]ï¼ˆRGBï¼‰
        mask_any: å¿½ç•¥åŒºåŸŸæ©ç  [1,1,H,W]
        mask_binary: äºŒå€¼åŒ–æ©è†œ [1,1,H,W]ï¼ˆNoneè¡¨ç¤ºæ— æ©è†œï¼‰
        original_alpha: åŸå§‹Aé€šé“ï¼ˆç”¨äºæœ€ç»ˆè¾“å‡ºRGBAï¼‰
    """
    # è¯»å–RGBAå›¾åƒï¼Œåˆ†ç¦»RGBå’ŒAé€šé“
    img_rgba = Image.open(img_path).convert("RGBA")
    img_rgb_pil = img_rgba.convert("RGB")  # å…ˆè½¬ä¸ºRGB
    original_alpha = np.array(img_rgba.split()[-1])  # æå–åŸå§‹Aé€šé“ï¼ˆ0=é€æ˜ï¼Œ255=ä¸é€æ˜ï¼‰

    # ç”¨Aé€šé“æ©è†œRGBï¼šA=0çš„åŒºåŸŸï¼ŒRGBè®¾ä¸º0ï¼ˆé»‘è‰²ï¼‰
    img_rgb_np = np.array(img_rgb_pil)
    alpha_mask = (original_alpha > 0)  # A>0çš„åŒºåŸŸä¿ç•™ï¼ŒA=0çš„åŒºåŸŸæ©è†œ
    img_rgb_masked_np = img_rgb_np * alpha_mask[..., np.newaxis]  # å¹¿æ’­æ©è†œåˆ°RGBä¸‰é€šé“
    img_rgb_masked = Image.fromarray(img_rgb_masked_np)  # æ©è†œåçš„RGBå›¾åƒ

    # å›¾åƒé¢„å¤„ç†æµç¨‹
    transform = transforms.Compose([
        transforms.Resize(size),
        transforms.ToTensor()
    ])
    tensor = transform(img_rgb_masked).unsqueeze(0)  # [1,3,H,W]ï¼ˆå·²ç”¨Aé€šé“æ©è†œï¼‰

    # å¤„ç†å¿½ç•¥å€¼
    if ignore_value is not None:
        ignore_norm = ignore_value / 255.0
        mask = (tensor == ignore_norm)
        tensor = tensor.clone()
        tensor[mask] = 0.0
        mask_any = mask.any(dim=1, keepdim=True)  # [1,1,H,W]
    else:
        mask_any = torch.zeros((1, 1, *tensor.shape[2:]), dtype=torch.bool)

    # æ©è†œé¢„å¤„ç†ï¼ˆå¦‚æœæœ‰å¤–éƒ¨æ©è†œæ–‡ä»¶ï¼Œä¼˜å…ˆçº§ä½äºAé€šé“ï¼‰
    if mask_path and os.path.exists(mask_path):
        mask_img = Image.open(mask_path).convert("L")  # è½¬ä¸ºç°åº¦å›¾
        mask_tensor = transforms.Resize(size)(mask_img)
        mask_tensor = transforms.ToTensor()(mask_tensor).unsqueeze(0)  # [1,1,H,W]
        mask_binary = (mask_tensor > 0).float()  # äºŒå€¼åŒ–ï¼šè£‚ç¼=1ï¼ŒèƒŒæ™¯=0
    else:
        mask_binary = None

    return img_rgb_masked, tensor, mask_any, mask_binary, original_alpha


def calculate_classification_metrics(prediction, target, threshold=0.25):
    """
    è®¡ç®—å¤šç±»åˆ«åˆ†ç±»æŒ‡æ ‡ï¼ˆèƒŒæ™¯ç±»=0ï¼Œè£‚ç¼ç±»=1ï¼‰
    Args:
        prediction: é¢„æµ‹ç»“æœï¼ˆå¼ é‡æˆ–numpyæ•°ç»„ï¼‰
        target: çœŸå®æ ‡ç­¾ï¼ˆå¼ é‡æˆ–numpyæ•°ç»„ï¼‰
        threshold: äºŒå€¼åŒ–é˜ˆå€¼
    Returns:
        åŒ…å«å…¨å±€æŒ‡æ ‡å’Œç±»åˆ«æŒ‡æ ‡çš„å­—å…¸
    """
    # è½¬ä¸ºnumpyæ•°ç»„å¹¶å±•å¹³
    if isinstance(prediction, torch.Tensor):
        prediction = prediction.cpu().numpy()
    if isinstance(target, torch.Tensor):
        target = target.cpu().numpy()

    pred_flat = prediction.flatten()
    target_flat = target.flatten()

    # äºŒå€¼åŒ–
    pred_binary = (pred_flat < threshold).astype(np.uint8)
    target_binary = (target_flat > 0).astype(np.uint8)

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(target_binary, pred_binary, labels=[0, 1])
    tn, fp, fn, tp = cm.ravel()
    total_pixels = len(pred_flat)

    # å…¨å±€æŒ‡æ ‡
    accuracy = (tp + tn) / total_pixels if total_pixels > 0 else 0

    # èƒŒæ™¯ç±»ï¼ˆ0ï¼‰æŒ‡æ ‡
    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0
    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0
    support_0 = tn + fp
    iou_0 = tn / (tn + fn + fp) if (tn + fn + fp) > 0 else 0

    # è£‚ç¼ç±»ï¼ˆ1ï¼‰æŒ‡æ ‡
    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0
    support_1 = tp + fn
    iou_1 = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0

    # å®è§‚/åŠ æƒå¹³å‡æŒ‡æ ‡
    macro_precision = (precision_0 + precision_1) / 2
    macro_recall = (recall_0 + recall_1) / 2
    macro_f1 = (f1_0 + f1_1) / 2

    weight_0 = support_0 / total_pixels if total_pixels > 0 else 0
    weight_1 = support_1 / total_pixels if total_pixels > 0 else 0
    weighted_precision = precision_0 * weight_0 + precision_1 * weight_1
    weighted_recall = recall_0 * weight_0 + recall_1 * weight_1
    weighted_f1 = f1_0 * weight_0 + f1_1 * weight_1

    # æ•´ä½“IoUå’ŒDice
    intersection_total = tp + tn
    union_total = tp + fp + fn + tn
    overall_iou = intersection_total / union_total if union_total > 0 else 0
    mean_iou = (iou_0 + iou_1) / 2
    dice = 2 * intersection_total / (2 * intersection_total + fp + fn) if (2 * intersection_total + fp + fn) > 0 else 0

    return {
        'overall': {
            'accuracy': accuracy,
            'overall_iou': overall_iou,
            'mean_iou': mean_iou,
            'dice': dice,
            'macro_precision': macro_precision,
            'macro_recall': macro_recall,
            'macro_f1': macro_f1,
            'weighted_precision': weighted_precision,
            'weighted_recall': weighted_recall,
            'weighted_f1': weighted_f1,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn,
            'total_pixels': total_pixels
        },
        'class_metrics': {
            0: {'precision': precision_0, 'recall': recall_0, 'f1_score': f1_0, 'support': support_0, 'iou': iou_0},
            1: {'precision': precision_1, 'recall': recall_1, 'f1_score': f1_1, 'support': support_1, 'iou': iou_1}
        }
    }


def calculate_pr_curve(predictions, targets):
    """
    è®¡ç®—ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿å’ŒAPå€¼
    Args:
        predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
        targets: çœŸå®æ ‡ç­¾åˆ—è¡¨
    Returns:
        ap: å¹³å‡ç²¾åº¦
        precision_vals: ç²¾ç¡®ç‡æ•°ç»„
        recall_vals: å¬å›ç‡æ•°ç»„
    """
    all_preds = []
    all_targets = []

    for pred, target in zip(predictions, targets):
        if isinstance(pred, torch.Tensor):
            pred = pred.cpu().numpy()
        if isinstance(target, torch.Tensor):
            target = target.cpu().numpy()

        all_preds.extend(pred.flatten())
        all_targets.extend(target.flatten())

    all_preds = np.array(all_preds)
    all_targets = np.array(all_targets)

    ap = average_precision_score(all_targets, all_preds)
    precision_vals, recall_vals, _ = precision_recall_curve(all_targets, all_preds)

    return ap, precision_vals, recall_vals


def create_elegant_metrics_plots(metrics_history, speed_metrics, save_dir):
    """
    åˆ›å»ºä¼˜é›…çš„æŒ‡æ ‡å¯è§†åŒ–å›¾è¡¨
    Args:
        metrics_history: æŒ‡æ ‡å†å²è®°å½•å­—å…¸
        speed_metrics: é€Ÿåº¦æŒ‡æ ‡å­—å…¸
        save_dir: å›¾è¡¨ä¿å­˜ç›®å½•
    Returns:
        å›¾è¡¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

    # 1. ä¸»è¦æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿', fontsize=16, fontweight='bold')

    # å‡†ç¡®ç‡å’ŒF1åˆ†æ•°
    if metrics_history['overall_accuracy'] and metrics_history['class_1_f1']:
        x_range = range(1, len(metrics_history['overall_accuracy']) + 1)
        axes[0, 0].plot(x_range, metrics_history['overall_accuracy'], 'o-', linewidth=2, markersize=4, label='å‡†ç¡®ç‡')
        axes[0, 0].plot(x_range, metrics_history['class_1_f1'], 's-', linewidth=2, markersize=4, label='è£‚ç¼F1')
        axes[0, 0].plot(x_range, metrics_history['class_0_f1'], '^-', linewidth=2, markersize=4, label='èƒŒæ™¯F1')
        axes[0, 0].plot(x_range, metrics_history['macro_f1'], 'v-', linewidth=2, markersize=4, label='å®è§‚F1')
        axes[0, 0].set_xlabel('å›¾åƒåºå·')
        axes[0, 0].set_ylabel('åˆ†æ•°')
        axes[0, 0].set_title('å‡†ç¡®ç‡ & F1åˆ†æ•°è¶‹åŠ¿')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].xaxis.set_major_locator(MaxNLocator(integer=True))

    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    if metrics_history['class_1_precision'] and metrics_history['class_1_recall']:
        x_range = range(1, len(metrics_history['class_1_precision']) + 1)
        axes[0, 1].plot(x_range, metrics_history['class_1_precision'], 'o-', linewidth=2, markersize=4,
                        label='è£‚ç¼ç²¾ç¡®ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_1_recall'], 's-', linewidth=2, markersize=4, label='è£‚ç¼å¬å›ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_0_precision'], '^-', linewidth=2, markersize=4,
                        label='èƒŒæ™¯ç²¾ç¡®ç‡')
        axes[0, 1].plot(x_range, metrics_history['class_0_recall'], 'd-', linewidth=2, markersize=4, label='èƒŒæ™¯å¬å›ç‡')
        axes[0, 1].set_xlabel('å›¾åƒåºå·')
        axes[0, 1].set_ylabel('åˆ†æ•°')
        axes[0, 1].set_title('ç²¾ç¡®ç‡ & å¬å›ç‡è¶‹åŠ¿')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].xaxis.set_major_locator(MaxNLocator(integer=True))

    # IoUå’ŒDiceç³»æ•°
    if metrics_history['class_1_iou'] and metrics_history['overall_dice']:
        x_range = range(1, len(metrics_history['class_1_iou']) + 1)
        axes[1, 0].plot(x_range, metrics_history['class_1_iou'], 'o-', linewidth=2, markersize=4, label='è£‚ç¼IoU')
        axes[1, 0].plot(x_range, metrics_history['class_0_iou'], 's-', linewidth=2, markersize=4, label='èƒŒæ™¯IoU')
        axes[1, 0].plot(x_range, metrics_history['mean_iou'], '^-', linewidth=2, markersize=4, label='å¹³å‡IoU')
        axes[1, 0].plot(x_range, metrics_history['overall_dice'], 'v-', linewidth=2, markersize=4, label='Diceç³»æ•°')
        axes[1, 0].set_xlabel('å›¾åƒåºå·')
        axes[1, 0].set_ylabel('åˆ†æ•°')
        axes[1, 0].set_title('åˆ†å‰²æŒ‡æ ‡è¶‹åŠ¿')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].xaxis.set_major_locator(MaxNLocator(integer=True))

    # æ¨ç†é€Ÿåº¦è¶‹åŠ¿
    if speed_metrics['inference_times']:
        x_range = range(1, len(speed_metrics['inference_times']) + 1)
        axes[1, 1].plot(x_range, speed_metrics['inference_times'], '^-', color='purple', linewidth=2, markersize=4,
                        label='æ¨ç†æ—¶é—´')
        axes[1, 1].set_xlabel('å›¾åƒåºå·')
        axes[1, 1].set_ylabel('æ—¶é—´ (ç§’)')
        axes[1, 1].set_title('æ¨ç†æ—¶é—´è¶‹åŠ¿')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].xaxis.set_major_locator(MaxNLocator(integer=True))

    plt.tight_layout()
    performance_plot_path = os.path.join(save_dir, "elegant_performance_metrics.png")
    plt.savefig(performance_plot_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # 2. é€Ÿåº¦æŒ‡æ ‡æ±‡æ€»å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig.suptitle('æ¨¡å‹æ¨ç†é€Ÿåº¦åˆ†æ', fontsize=16, fontweight='bold')

    # æ¨ç†æ—¶é—´åˆ†å¸ƒ
    if speed_metrics['inference_times']:
        axes[0].hist(speed_metrics['inference_times'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0].axvline(np.mean(speed_metrics['inference_times']), color='red', linestyle='--', linewidth=2,
                        label=f'å¹³å‡æ—¶é—´: {np.mean(speed_metrics["inference_times"]):.4f}s')
        axes[0].set_xlabel('æ¨ç†æ—¶é—´ (ç§’)')
        axes[0].set_ylabel('é¢‘æ¬¡')
        axes[0].set_title('æ¨ç†æ—¶é—´åˆ†å¸ƒ')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

    # FPSåˆ†å¸ƒ
    if speed_metrics['fps_list']:
        axes[1].hist(speed_metrics['fps_list'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[1].axvline(np.mean(speed_metrics['fps_list']), color='red', linestyle='--', linewidth=2,
                        label=f'å¹³å‡FPS: {np.mean(speed_metrics["fps_list"]):.2f}')
        axes[1].set_xlabel('FPS')
        axes[1].set_ylabel('é¢‘æ¬¡')
        axes[1].set_title('FPSåˆ†å¸ƒ')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    speed_plot_path = os.path.join(save_dir, "elegant_speed_analysis.png")
    plt.savefig(speed_plot_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # 3. ç±»åˆ«æ€§èƒ½å¯¹æ¯”å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig.suptitle('ç±»åˆ«æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')

    # ç²¾ç¡®ç‡å’Œå¬å›ç‡å¯¹æ¯”
    categories = ['èƒŒæ™¯', 'è£‚ç¼']
    precision_values = [np.mean(metrics_history['class_0_precision']), np.mean(metrics_history['class_1_precision'])]
    recall_values = [np.mean(metrics_history['class_0_recall']), np.mean(metrics_history['class_1_recall'])]

    x = np.arange(len(categories))
    width = 0.35

    axes[0].bar(x - width / 2, precision_values, width, label='ç²¾ç¡®ç‡', alpha=0.7)
    axes[0].bar(x + width / 2, recall_values, width, label='å¬å›ç‡', alpha=0.7)
    axes[0].set_xlabel('ç±»åˆ«')
    axes[0].set_ylabel('åˆ†æ•°')
    axes[0].set_title('å„ç±»åˆ«ç²¾ç¡®ç‡å’Œå¬å›ç‡')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(categories)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # F1åˆ†æ•°å’ŒIoUå¯¹æ¯”
    f1_values = [np.mean(metrics_history['class_0_f1']), np.mean(metrics_history['class_1_f1'])]
    iou_values = [np.mean(metrics_history['class_0_iou']), np.mean(metrics_history['class_1_iou'])]

    axes[1].bar(x - width / 2, f1_values, width, label='F1åˆ†æ•°', alpha=0.7)
    axes[1].bar(x + width / 2, iou_values, width, label='IoU', alpha=0.7)
    axes[1].set_xlabel('ç±»åˆ«')
    axes[1].set_ylabel('åˆ†æ•°')
    axes[1].set_title('å„ç±»åˆ«F1åˆ†æ•°å’ŒIoU')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(categories)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    class_comparison_path = os.path.join(save_dir, "class_performance_comparison.png")
    plt.savefig(class_comparison_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"ğŸ¨ ä¼˜é›…æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}")
    return [performance_plot_path, speed_plot_path, class_comparison_path]


def save_pure_heatmap(data, original_img, save_path):
    """
    ä¿å­˜çº¯çƒ­å›¾ï¼ˆä¸å åŠ åŸå›¾ï¼‰ï¼Œå°ºå¯¸ä¸åŸå›¾ä¸€è‡´
    Args:
        data: çƒ­å›¾æ•°æ®ï¼ˆå¼ é‡æˆ–numpyæ•°ç»„ï¼‰
        original_img: åŸå§‹PILå›¾åƒ
        save_path: ä¿å­˜è·¯å¾„
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    # æ•°æ®é¢„å¤„ç†
    if isinstance(data, torch.Tensor):
        data = data.squeeze().cpu().numpy()

    # å½’ä¸€åŒ–åˆ°0-255
    norm = (data - data.min()) / (data.max() - data.min() + 1e-8)
    heatmap_uint8 = (norm * 255).astype(np.uint8)

    # è°ƒæ•´å°ºå¯¸å¹¶ç”Ÿæˆå½©è‰²çƒ­å›¾
    orig_w, orig_h = original_img.size
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_color = cv2.resize(heatmap_color, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)

    cv2.imwrite(save_path, heatmap_color)
    print(f"å·²ä¿å­˜çº¯çƒ­å›¾: {save_path}")


def save_image(attn_tensor, mask_tensor, save_path, original_img=None, original_alpha=None,
               keep_white=True, heat_threshold=0.18, blend_alpha=0.8,
               enhance_strength=3.5, soften=False, soften_ksize=15):
    """
    ç¨³å¥ç‰ˆï¼šä»…å°† attn ä¸­ > heat_threshold çš„åƒç´ å¯¹åŸå›¾å¯¹åº”ä½ç½®è¿›è¡Œé»‘è‰²åŠ æ·±å¤„ç†ï¼ˆè®©åŒºåŸŸæ›´é»‘ï¼‰
    æ ¸å¿ƒä¿®æ”¹ï¼šè¾“å‡ºRGBAæ ¼å¼ï¼Œå¤ç”¨åŸå§‹Aé€šé“
    Args:
        attn_tensor: æ³¨æ„åŠ›å¼ é‡
        mask_tensor: æ©è†œå¼ é‡
        save_path: ä¿å­˜è·¯å¾„
        original_img: åŸå§‹å›¾åƒï¼ˆPILæˆ–numpyæ•°ç»„ï¼‰
        original_alpha: åŸå§‹Aé€šé“ï¼ˆnumpyæ•°ç»„ï¼Œæ¥è‡ªè¾“å…¥RGBAï¼‰
        keep_white: æ©è†œåŒºåŸŸæ˜¯å¦æ˜¾ç¤ºç™½è‰²
        heat_threshold: æ³¨æ„åŠ›é˜ˆå€¼
        blend_alpha: æ··åˆé€æ˜åº¦
        enhance_strength: åŠ æ·±å¼ºåº¦
        soften: æ˜¯å¦è½¯åŒ–æ©ç 
        soften_ksize: è½¯åŒ–æ ¸å¤§å°
    Returns:
        å¤„ç†åçš„RGBAå›¾åƒï¼ˆnumpyæ•°ç»„ï¼‰
    """
    # åˆ›å»ºä¿å­˜ç›®å½•
    dirpath = os.path.dirname(save_path)
    if dirpath:
        os.makedirs(dirpath, exist_ok=True)

    # éªŒè¯è¾“å…¥å›¾åƒ
    if original_img is None:
        raise ValueError("original_img ä¸èƒ½ä¸ºç©ºã€‚")
    if isinstance(original_img, Image.Image):
        img_rgb = np.array(original_img.convert("RGB"))
    else:
        img_rgb = np.asarray(original_img)
        if img_rgb.ndim == 2:
            img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_GRAY2RGB)
        elif img_rgb.shape[2] == 4:
            img_rgb = img_rgb[..., :3]

    # éªŒè¯Aé€šé“ï¼ˆç¡®ä¿è¾“å‡ºRGBAï¼‰
    if original_alpha is None:
        # è‹¥æœªæä¾›åŸå§‹Aé€šé“ï¼Œé»˜è®¤å…¨ä¸é€æ˜ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
        original_alpha = np.ones((img_rgb.shape[0], img_rgb.shape[1]), dtype=np.uint8) * 255
    else:
        # è°ƒæ•´Aé€šé“å°ºå¯¸ä¸RGBä¸€è‡´
        original_alpha = cv2.resize(original_alpha, (img_rgb.shape[1], img_rgb.shape[0]),
                                    interpolation=cv2.INTER_NEAREST)

    # è½¬æ¢é¢œè‰²ç©ºé—´
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    H, W = img_bgr.shape[:2]

    # æ³¨æ„åŠ›å¼ é‡é¢„å¤„ç†
    if isinstance(attn_tensor, torch.Tensor):
        attn_np = attn_tensor.detach().cpu().numpy()
    else:
        attn_np = np.asarray(attn_tensor)

    # é™ç»´å¤„ç†
    while attn_np.ndim > 2:
        attn_np = attn_np.mean(axis=0)
    attn_np = attn_np.astype(np.float32)

    # å¤„ç†å¼‚å¸¸å€¼
    if not np.isfinite(attn_np).all():
        attn_np = np.nan_to_num(attn_np, nan=0.0, posinf=0.0, neginf=0.0)
    mn = float(np.nanmin(attn_np)) if attn_np.size else 0.0
    mx = float(np.nanmax(attn_np)) if attn_np.size else 0.0
    if mx - mn < 1e-8:
        attn_norm = np.zeros_like(attn_np, dtype=np.float32)
    else:
        attn_norm = (attn_np - mn) / (mx - mn)

    # è°ƒæ•´å°ºå¯¸
    attn_resized = cv2.resize(attn_norm.astype(np.float32), (W, H), interpolation=cv2.INTER_LINEAR)

    # ç”Ÿæˆçƒ­åŠ›æ©ç ï¼ˆè¶Šå†·çš„åœ°æ–¹ï¼ˆattnè¶Šå°ï¼‰ï¼Œè¶ŠåŠ æ·±ï¼‰
    heat_mask = (attn_resized < float(heat_threshold))  # å†·åŒºåŸŸæ©ç 
    if soften:
        k = soften_ksize if (soften_ksize % 2 == 1) else (soften_ksize + 1)
        heat_mask_float = cv2.GaussianBlur(heat_mask.astype(np.float32), (k, k), 0)
        heat_alpha = np.clip(heat_mask_float, 0.0, 1.0) * float(blend_alpha)
    else:
        heat_alpha = heat_mask.astype(np.float32) * float(blend_alpha)

    # -------------------------- æ ¸å¿ƒé»‘è‰²åŠ æ·±é€»è¾‘ --------------------------
    black_template = np.zeros_like(img_bgr, dtype=np.uint8)
    darken_factor = 1.0 + (enhance_strength - 1.0) * heat_alpha  # å†·åŒºåŸŸåŠ æ·±ç³»æ•°æ›´å¤§
    darken_factor = np.clip(darken_factor, 1.0, None)

    img_float = img_bgr.astype(np.float32)
    darken_factor_3d = darken_factor[..., np.newaxis]
    darkened_bgr = np.clip(img_float / darken_factor_3d, 0, 255).astype(np.uint8)
    # --------------------------------------------------------------------------

    # åº”ç”¨åŠ æ·±æ•ˆæœ
    overlay = img_bgr.copy()
    mask_idxs = heat_mask
    if mask_idxs.any():
        original_pixels = img_bgr[mask_idxs].astype(np.float32)
        darkened_pixels = darkened_bgr[mask_idxs].astype(np.float32)
        alpha_values = heat_alpha[mask_idxs][:, np.newaxis]
        blended_pixels = (original_pixels * (1.0 - alpha_values) +
                          darkened_pixels * alpha_values).astype(np.uint8)
        overlay[mask_idxs] = blended_pixels

    # åº”ç”¨æ©è†œç€è‰²
    if mask_tensor is not None:
        if isinstance(mask_tensor, torch.Tensor):
            mask_np = mask_tensor.detach().cpu().numpy()
        else:
            mask_np = np.asarray(mask_tensor)

        mask_np = np.squeeze(mask_np)
        while mask_np.ndim > 2:
            mask_np = mask_np.any(axis=0)
        mask_resized = cv2.resize(mask_np.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)

        if mask_resized.any():
            overlay[mask_resized] = (255, 255, 255) if keep_white else (0, 0, 0)

    # -------------------------- æ ¸å¿ƒä¿®æ”¹ï¼šè¾“å‡ºRGBA --------------------------
    # è½¬æ¢å›RGBï¼Œåˆå¹¶åŸå§‹Aé€šé“
    # overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)
    overlay_rgba = np.dstack((overlay, original_alpha))  # åˆå¹¶RGB+åŸå§‹Aé€šé“
    # --------------------------------------------------------------------------

    # ä¿å­˜RGBAå›¾åƒï¼ˆå¿…é¡»ä¸ºPNGæ ¼å¼ï¼ŒJPGä¸æ”¯æŒé€æ˜ï¼‰
    overlay_rgba = overlay_rgba.astype(np.uint8)
    cv2.imwrite(save_path, overlay_rgba)
    print(f"å·²ä¿å­˜RGBAç»“æœå›¾: {save_path}")

    return overlay_rgba


def find_mask_for_image(img_path, mask_dir):
    """
    æ ¹æ®å›¾åƒæ–‡ä»¶åæ‰¾åˆ°å¯¹åº”çš„æ©è†œæ–‡ä»¶
    é€‚é…å‘½åçº¦å®šï¼šimage: '20160222_080850.jpg' -> mask: '20160222_080850_mask.png'
    Args:
        img_path: å›¾åƒè·¯å¾„
        mask_dir: æ©è†œç›®å½•
    Returns:
        æ‰¾åˆ°çš„æ©è†œè·¯å¾„ï¼ˆNoneè¡¨ç¤ºæœªæ‰¾åˆ°ï¼‰
    """
    img_name = os.path.basename(img_path)
    base_name = os.path.splitext(img_name)[0]

    # å¯èƒ½çš„æ©è†œæ–‡ä»¶åæ¨¡å¼
    possible_mask_names = [
        f"{base_name}_mask.png",
        f"{base_name}_mask.jpg",
        f"{base_name}.png",
        f"{base_name}.jpg",
        base_name + '.png',
        base_name + '.jpg'
    ]

    for mask_name in possible_mask_names:
        mask_path = os.path.join(mask_dir, mask_name)
        if os.path.exists(mask_path):
            return mask_path

    return None


def calculate_average_metrics(metrics_list):
    """
    è®¡ç®—æŒ‡æ ‡åˆ—è¡¨çš„å¹³å‡å€¼ï¼Œåªå¤„ç†æ•°å€¼ç±»å‹çš„æŒ‡æ ‡
    Args:
        metrics_list: æŒ‡æ ‡å­—å…¸åˆ—è¡¨
    Returns:
        å¹³å‡æŒ‡æ ‡å­—å…¸
    """
    if not metrics_list:
        return {}

    # è·å–æ‰€æœ‰æ•°å€¼ç±»å‹çš„é”®
    numeric_keys = []
    for key in metrics_list[0].keys():
        if isinstance(metrics_list[0][key], (int, float, np.number)):
            numeric_keys.append(key)

    # è®¡ç®—å¹³å‡å€¼
    avg_metrics = {}
    for key in numeric_keys:
        try:
            avg_metrics[key] = np.mean([m[key] for m in metrics_list])
        except (TypeError, ValueError):
            continue

    return avg_metrics


@torch.no_grad()
def test_fgem_with_mask(
        model_path,
        input_path,
        mask_dir=None,
        device="cuda",
        save_dir_input="./run/predict_heatmap/input",
        save_dir_output="./run/predict_heatmap/output",
        save_dir_orig="./run/predict_images/original",
        save_dir_result="./run/predict_images/result",
        save_dir_metrics="./run/metrics",
        eval_threshold=0.25
):
    """
    æµ‹è¯•FGEMæ¨¡å‹ï¼ˆå¸¦æ©è†œè¯„ä¼°ï¼‰
    æ ¸å¿ƒä¿®æ”¹ï¼š
    1. è¾“å…¥RGBAå›¾åƒï¼Œç”¨Aé€šé“æ©è†œRGBåè¾“å…¥æ¨¡å‹
    2. è¾“å‡ºRGBAæ ¼å¼ç»“æœï¼ˆå¤ç”¨åŸå§‹Aé€šé“ï¼‰
    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        input_path: è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼ŒRGBAæ ¼å¼ï¼‰
        mask_dir: æ©è†œç›®å½•ï¼ˆNoneè¡¨ç¤ºä¸è¯„ä¼°ï¼‰
        device: è¿è¡Œè®¾å¤‡ï¼ˆcuda/cpuï¼‰
        save_dir_input: è¾“å…¥çƒ­å›¾ä¿å­˜ç›®å½•
        save_dir_output: è¾“å‡ºçƒ­å›¾ä¿å­˜ç›®å½•
        save_dir_orig: åŸå§‹å›¾åƒä¿å­˜ç›®å½•
        save_dir_result: ç»“æœå›¾åƒä¿å­˜ç›®å½•ï¼ˆRGBAæ ¼å¼ï¼‰
        save_dir_metrics: æŒ‡æ ‡ä¿å­˜ç›®å½•
        eval_threshold: è¯„ä¼°é˜ˆå€¼
    """
    # åŠ è½½æ¨¡å‹
    model = load_model(model_path, device)

    # åˆå§‹åŒ–æŒ‡æ ‡å­˜å‚¨
    all_overall_metrics = []
    all_class_metrics = {0: [], 1: []}
    metrics_history = {
        'overall_accuracy': [], 'overall_iou': [], 'mean_iou': [], 'overall_dice': [],
        'macro_precision': [], 'macro_recall': [], 'macro_f1': [],
        'weighted_precision': [], 'weighted_recall': [], 'weighted_f1': [],
        'class_0_precision': [], 'class_0_recall': [], 'class_0_f1': [], 'class_0_iou': [],
        'class_1_precision': [], 'class_1_recall': [], 'class_1_f1': [], 'class_1_iou': []
    }
    speed_metrics = {
        'inference_times': [], 'fps_list': [], 'preprocess_times': [], 'postprocess_times': []
    }
    all_predictions = []
    all_targets = []

    # è·å–å›¾åƒåˆ—è¡¨
    if os.path.isdir(input_path):
        img_list = [os.path.join(input_path, f)
                    for f in os.listdir(input_path)
                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))]  # åŒ…å«å¸¸è§å›¾åƒæ ¼å¼
    else:
        img_list = [input_path]

    valid_count = 0
    missing_masks = []

    # æ‰¹é‡å¤„ç†å›¾åƒ
    for img_path in tqdm(img_list, desc="Testing FGEM"):
        # æŸ¥æ‰¾å¯¹åº”çš„æ©è†œæ–‡ä»¶
        mask_path = find_mask_for_image(img_path, mask_dir) if mask_dir else None
        if mask_dir and mask_path is None:
            missing_masks.append(os.path.basename(img_path))
            print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”æ©è†œæ–‡ä»¶: {os.path.basename(img_path)}")

        # é¢„å¤„ç†è®¡æ—¶ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šè·å–åŸå§‹Aé€šé“ï¼‰
        preprocess_start = time.perf_counter()
        original_img, tensor, ignore_mask, mask_binary, original_alpha = preprocess_image_and_mask(
            img_path, mask_path, ignore_value=None
        )
        tensor = tensor.to(device)
        ignore_mask = ignore_mask.to(device)
        preprocess_time = time.perf_counter() - preprocess_start
        speed_metrics['preprocess_times'].append(preprocess_time)

        # æ¨ç†è®¡æ—¶
        inference_start = time.perf_counter()
        out = model(tensor)
        attn_map = out.mean(dim=1, keepdim=True)
        inference_time = time.perf_counter() - inference_start
        speed_metrics['inference_times'].append(inference_time)
        speed_metrics['fps_list'].append(1.0 / inference_time)

        # åå¤„ç†è®¡æ—¶
        postprocess_start = time.perf_counter()

        # ä¿å­˜åŸå§‹å›¾åƒï¼ˆä¿ç•™RGBAæ ¼å¼ï¼‰
        orig_save_path = os.path.join(save_dir_orig, os.path.basename(img_path))
        os.makedirs(os.path.dirname(orig_save_path), exist_ok=True)
        # è¯»å–åŸå§‹RGBAå›¾åƒå¹¶ä¿å­˜ï¼ˆç¡®ä¿åŸå§‹é€æ˜åº¦ä¸å˜ï¼‰
        original_rgba = Image.open(img_path).convert("RGBA")
        original_rgba.save(orig_save_path)

        # ä¿å­˜ç»“æœå›¾åƒï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šä¼ å…¥åŸå§‹Aé€šé“ï¼Œè¾“å‡ºRGBAï¼‰
        result_save_path = os.path.join(save_dir_result, os.path.splitext(os.path.basename(img_path))[0] + ".png")
        save_image(
            attn_map, ignore_mask, result_save_path,
            original_img=original_img,
            original_alpha=original_alpha,  # ä¼ å…¥åŸå§‹Aé€šé“
            keep_white=True
        )

        # ä¿å­˜è¾“å…¥çƒ­å›¾
        input_gray = tensor.mean(dim=1, keepdim=True)
        input_heatmap_path = os.path.join(
            save_dir_input, f"{os.path.splitext(os.path.basename(img_path))[0]}_input_heatmap.png"
        )
        save_pure_heatmap(input_gray, original_img, input_heatmap_path)

        # ä¿å­˜è¾“å‡ºçƒ­å›¾
        output_heatmap_path = os.path.join(
            save_dir_output, f"{os.path.splitext(os.path.basename(img_path))[0]}_output_heatmap.png"
        )
        save_pure_heatmap(attn_map, original_img, output_heatmap_path)

        postprocess_time = time.perf_counter() - postprocess_start
        speed_metrics['postprocess_times'].append(postprocess_time)

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆæœ‰æ©è†œæ—¶ï¼‰
        if mask_binary is not None:
            # è°ƒæ•´é¢„æµ‹ç»“æœå°ºå¯¸
            pred_resized = torch.nn.functional.interpolate(
                attn_map, size=mask_binary.shape[2:], mode='bilinear', align_corners=False
            )

            # è®¡ç®—æŒ‡æ ‡
            metrics_result = calculate_classification_metrics(pred_resized, mask_binary, threshold=eval_threshold)

            # æ›´æ–°æŒ‡æ ‡å­˜å‚¨
            all_overall_metrics.append(metrics_result['overall'])
            for class_id in [0, 1]:
                all_class_metrics[class_id].append(metrics_result['class_metrics'][class_id])

            # æ›´æ–°æŒ‡æ ‡å†å²
            metrics_history['overall_accuracy'].append(metrics_result['overall']['accuracy'])
            metrics_history['overall_iou'].append(metrics_result['overall']['overall_iou'])
            metrics_history['mean_iou'].append(metrics_result['overall']['mean_iou'])
            metrics_history['overall_dice'].append(metrics_result['overall']['dice'])
            metrics_history['macro_precision'].append(metrics_result['overall']['macro_precision'])
            metrics_history['macro_recall'].append(metrics_result['overall']['macro_recall'])
            metrics_history['macro_f1'].append(metrics_result['overall']['macro_f1'])
            metrics_history['weighted_precision'].append(metrics_result['overall']['weighted_precision'])
            metrics_history['weighted_recall'].append(metrics_result['overall']['weighted_recall'])
            metrics_history['weighted_f1'].append(metrics_result['overall']['weighted_f1'])
            metrics_history['class_0_precision'].append(metrics_result['class_metrics'][0]['precision'])
            metrics_history['class_0_recall'].append(metrics_result['class_metrics'][0]['recall'])
            metrics_history['class_0_f1'].append(metrics_result['class_metrics'][0]['f1_score'])
            metrics_history['class_0_iou'].append(metrics_result['class_metrics'][0]['iou'])
            metrics_history['class_1_precision'].append(metrics_result['class_metrics'][1]['precision'])
            metrics_history['class_1_recall'].append(metrics_result['class_metrics'][1]['recall'])
            metrics_history['class_1_f1'].append(metrics_result['class_metrics'][1]['f1_score'])
            metrics_history['class_1_iou'].append(metrics_result['class_metrics'][1]['iou'])

            # å­˜å‚¨é¢„æµ‹å’Œç›®æ ‡å€¼
            all_predictions.append(pred_resized)
            all_targets.append(mask_binary)

            valid_count += 1

            # æ‰“å°å•å›¾ç»“æœ
            print(f"{os.path.basename(img_path)} - "
                  f"è£‚ç¼F1: {metrics_result['class_metrics'][1]['f1_score']:.4f}, "
                  f"èƒŒæ™¯F1: {metrics_result['class_metrics'][0]['f1_score']:.4f}, "
                  f"å®è§‚F1: {metrics_result['overall']['macro_f1']:.4f}, "
                  f"æ¨ç†æ—¶é—´: {inference_time:.4f}s, FPS: {1.0 / inference_time:.2f}")

    # è¾“å‡ºæ±‡æ€»ç»“æœ
    if valid_count > 0:
        print("\n" + "=" * 80)
        print("æ¨¡å‹è¯„ä¼°ç»“æœæ±‡æ€»ï¼ˆåˆ†ç±»è§†è§’ï¼‰")
        print("=" * 80)

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_overall = calculate_average_metrics(all_overall_metrics)
        avg_class_0 = calculate_average_metrics(all_class_metrics[0])
        avg_class_1 = calculate_average_metrics(all_class_metrics[1])

        # è®¡ç®—é€Ÿåº¦æŒ‡æ ‡
        avg_speed_metrics = {
            'avg_inference_time': np.mean(speed_metrics['inference_times']),
            'std_inference_time': np.std(speed_metrics['inference_times']),
            'avg_fps': np.mean(speed_metrics['fps_list']),
            'std_fps': np.std(speed_metrics['fps_list']),
            'avg_preprocess_time': np.mean(speed_metrics['preprocess_times']),
            'avg_postprocess_time': np.mean(speed_metrics['postprocess_times']),
            'min_inference_time': np.min(speed_metrics['inference_times']),
            'max_inference_time': np.max(speed_metrics['inference_times']),
            'total_inference_time': np.sum(speed_metrics['inference_times'])
        }

        # æ‰“å°å…¨å±€æŒ‡æ ‡
        print(f"æµ‹è¯•å›¾åƒæ•°é‡: {valid_count}")
        print(f"\nå…¨å±€æŒ‡æ ‡:")
        print(f"   å‡†ç¡®ç‡ (Accuracy): {avg_overall['accuracy']:.4f}")
        print(f"   æ•´ä½“IoU: {avg_overall['overall_iou']:.4f}")
        print(f"   å¹³å‡IoU: {avg_overall['mean_iou']:.4f}")
        print(f"   Diceç³»æ•°: {avg_overall['dice']:.4f}")
        print(f"   å®è§‚ç²¾ç¡®ç‡: {avg_overall['macro_precision']:.4f}")
        print(f"   å®è§‚å¬å›ç‡: {avg_overall['macro_recall']:.4f}")
        print(f"   å®è§‚F1åˆ†æ•°: {avg_overall['macro_f1']:.4f}")
        print(f"   åŠ æƒç²¾ç¡®ç‡: {avg_overall['weighted_precision']:.4f}")
        print(f"   åŠ æƒå¬å›ç‡: {avg_overall['weighted_recall']:.4f}")
        print(f"   åŠ æƒF1åˆ†æ•°: {avg_overall['weighted_f1']:.4f}")

        # æ‰“å°ç±»åˆ«æŒ‡æ ‡
        print(f"\nèƒŒæ™¯ç±»åˆ«æŒ‡æ ‡ (ç±»åˆ« 0):")
        print(f"   ç²¾ç¡®ç‡: {avg_class_0['precision']:.4f}")
        print(f"   å¬å›ç‡: {avg_class_0['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {avg_class_0['f1_score']:.4f}")
        print(f"   IoU: {avg_class_0['iou']:.4f}")
        print(f"   æ”¯æŒåº¦: {avg_class_0['support']:.0f} åƒç´ ")

        print(f"\nè£‚ç¼ç±»åˆ«æŒ‡æ ‡ (ç±»åˆ« 1):")
        print(f"   ç²¾ç¡®ç‡: {avg_class_1['precision']:.4f}")
        print(f"   å¬å›ç‡: {avg_class_1['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {avg_class_1['f1_score']:.4f}")
        print(f"   IoU: {avg_class_1['iou']:.4f}")
        print(f"   æ”¯æŒåº¦: {avg_class_1['support']:.0f} åƒç´ ")

        # æ‰“å°é€Ÿåº¦æŒ‡æ ‡
        print(f"\né€Ÿåº¦æ€§èƒ½æŒ‡æ ‡:")
        print(
            f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_speed_metrics['avg_inference_time']:.4f}s Â± {avg_speed_metrics['std_inference_time']:.4f}s")
        print(f"   æœ€å¿«æ¨ç†æ—¶é—´: {avg_speed_metrics['min_inference_time']:.4f}s")
        print(f"   æœ€æ…¢æ¨ç†æ—¶é—´: {avg_speed_metrics['max_inference_time']:.4f}s")
        print(f"   å¹³å‡FPS: {avg_speed_metrics['avg_fps']:.2f} Â± {avg_speed_metrics['std_fps']:.2f}")
        print(f"   å¹³å‡é¢„å¤„ç†æ—¶é—´: {avg_speed_metrics['avg_preprocess_time']:.4f}s")
        print(f"   å¹³å‡åå¤„ç†æ—¶é—´: {avg_speed_metrics['avg_postprocess_time']:.4f}s")
        print(f"   æ€»æ¨ç†æ—¶é—´: {avg_speed_metrics['total_inference_time']:.2f}s")

        # æ··æ·†çŸ©é˜µç»Ÿè®¡
        total_tp = sum(m['tp'] for m in all_overall_metrics)
        total_fp = sum(m['fp'] for m in all_overall_metrics)
        total_fn = sum(m['fn'] for m in all_overall_metrics)
        total_tn = sum(m['tn'] for m in all_overall_metrics)
        total_pixels = sum(m['total_pixels'] for m in all_overall_metrics)

        print(f"\næ··æ·†çŸ©é˜µç»Ÿè®¡:")
        print(f"   çœŸé˜³æ€§ (TP): {total_tp}")
        print(f"   å‡é˜³æ€§ (FP): {total_fp}")
        print(f"   å‡é˜´æ€§ (FN): {total_fn}")
        print(f"   çœŸé˜´æ€§ (TN): {total_tn}")
        print(f"   æ€»åƒç´ æ•°: {total_pixels}")

        # è®¡ç®—PRæ›²çº¿å’ŒAP
        ap, precision_curve, recall_curve = calculate_pr_curve(all_predictions, all_targets)
        print(f"å¹³å‡ç²¾åº¦ (AP): {ap:.4f}")

        # ä¿å­˜æŒ‡æ ‡ç»“æœ
        os.makedirs(save_dir_metrics, exist_ok=True)
        metrics_file = os.path.join(save_dir_metrics, "evaluation_results.txt")
        with open(metrics_file, 'w', encoding='utf-8') as f:
            f.write("æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆåˆ†ç±»è§†è§’ï¼‰\n")
            f.write("=" * 50 + "\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°é‡: {valid_count}\n")
            f.write(f"è¯„ä¼°é˜ˆå€¼: {eval_threshold}\n\n")

            f.write("å…¨å±€æŒ‡æ ‡:\n")
            for key, value in avg_overall.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nèƒŒæ™¯ç±»åˆ«æŒ‡æ ‡:\n")
            for key, value in avg_class_0.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nè£‚ç¼ç±»åˆ«æŒ‡æ ‡:\n")
            for key, value in avg_class_1.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\né€Ÿåº¦æŒ‡æ ‡:\n")
            for key, value in avg_speed_metrics.items():
                f.write(f"{key}: {value:.4f}\n")

            f.write(f"\nAP: {ap:.4f}\n")
            f.write(f"\næ··æ·†çŸ©é˜µ:\n")
            f.write(f"TP: {total_tp}\n")
            f.write(f"FP: {total_fp}\n")
            f.write(f"FN: {total_fn}\n")
            f.write(f"TN: {total_tn}\n")
            f.write(f"æ€»åƒç´ æ•°: {total_pixels}\n")

            if missing_masks:
                f.write(f"\nç¼ºå¤±æ©è†œçš„æ–‡ä»¶ ({len(missing_masks)} ä¸ª):\n")
                for missing in missing_masks:
                    f.write(f"{missing}\n")

        print(f"æŒ‡æ ‡ç»“æœå·²ä¿å­˜: {metrics_file}")

        # ä¿å­˜å¯è§†åŒ–å›¾è¡¨
        elegant_plots = create_elegant_metrics_plots(metrics_history, speed_metrics, save_dir_metrics)
        print(f"ä¼˜é›…æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜: {elegant_plots}")

        # ä¿å­˜PRæ›²çº¿
        plt.figure(figsize=(10, 8))
        plt.plot(recall_curve, precision_curve, 'b-', linewidth=2, label=f'PR curve (AP = {ap:.4f})')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend()
        plt.grid(True)
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        pr_curve_path = os.path.join(save_dir_metrics, "pr_curve.png")
        plt.savefig(pr_curve_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"PRæ›²çº¿å·²ä¿å­˜: {pr_curve_path}")

        # æ‰“å°ç¼ºå¤±æ©è†œä¿¡æ¯
        if missing_masks:
            print(f"\næœ‰ {len(missing_masks)} ä¸ªå›¾åƒæœªæ‰¾åˆ°å¯¹åº”æ©è†œæ–‡ä»¶")

    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ©è†œæ–‡ä»¶ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—")


# é…ç½®è·¯å¾„
pre_dir = 'D:/myDataManager/pycharmProject/Crack-Segmentation/road_roi_net/RoadDataset/train/paper3_select/ROI/123___jpg__/frames'

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®ï¼ˆé»˜è®¤æ³¨é‡Šä¸€ä¸ªï¼Œå¯ç”¨å¦ä¸€ä¸ªï¼‰
    # test_fgem_with_mask(
    #     model_path="./checkpoints/best_checkpoint.pth",
    #     input_path=r'D:/myDataManager/pycharmProject/Crack-Segmentation/FGEM/IOT_duikangGenerateNet/images',
    #     mask_dir=r'D:/myDataManager/pycharmProject/Crack-Segmentation/FGEM/IOT_duikangGenerateNet/images',
    #     device="cuda:0" if torch.cuda.is_available() else "cpu",
    #     save_dir_input=pre_dir + "/predict_heatmap/input",
    #     save_dir_output=pre_dir + "/predict_heatmap/output",
    #     save_dir_orig=pre_dir + "/predict_images/original",
    #     save_dir_result=pre_dir + "/predict_images/result",
    #     save_dir_metrics=pre_dir + "/metrics",
    #     eval_threshold=0.25
    # )

    test_fgem_with_mask(
        model_path="./checkpoints/best_checkpoint.pth",
        input_path=r'D:\myDataManager\pycharmProject\Crack-Segmentation\road_roi_net\RoadDataset\train\paper3_select\ROI\123___jpg__\frames',
        mask_dir=r'D:\myDataManager\pycharmProject\Crack-Segmentation\road_roi_net\RoadDataset\train\paper3_select\ROI\123___jpg__\frames',
        device="cuda:0" if torch.cuda.is_available() else "cpu",
        save_dir_input=pre_dir + "/predict_heatmap/input",
        save_dir_output=pre_dir + "/predict_heatmap/output",
        save_dir_orig=pre_dir + "/predict_images/original",
        save_dir_result=pre_dir + "/predict_images/result",
        save_dir_metrics=pre_dir + "/metrics",
        eval_threshold=0.25
    )